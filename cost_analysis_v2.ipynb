{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc # SQL Connection\n",
    "import sqlCredentials as sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCUREMENTDB\n",
    "\n",
    "proc_db = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'Server=52.86.56.66;'\n",
    "    'Database=PROCUREMENTDB;'\n",
    "    'UID='+sql.username+';'\n",
    "    'PWD='+sql.password+';'\n",
    "    'Trusted_connection=no;'\n",
    ")\n",
    "\n",
    "#BookXCenterProduction\n",
    "prod_db = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'Server=52.86.56.66;'\n",
    "    'Database=BookXCenterProduction;'\n",
    "    'UID='+sql.username+';'\n",
    "    'PWD='+sql.password+';'\n",
    "    'Trusted_connection=no;'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Clean up tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(phrase):\n",
    "    phrase = phrase.lstrip()\n",
    "    phrase = phrase.rstrip()\n",
    "    phrase = phrase.upper()\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary\n",
    "pub_dict = \"\"\"\n",
    "SELECT *\n",
    "FROM dbo.PublisherDictionary\n",
    "\"\"\"\n",
    "# LP All currencies\n",
    "all_lp = \"\"\"\n",
    "SELECT\n",
    "\t[Isbn]\n",
    "\t,[Currency]\n",
    "\t,[Price]\n",
    "FROM\n",
    "\t[Isbn].[ListPrice]\n",
    "\"\"\"\n",
    "# Bibliography\n",
    "bilblo_sql = \"\"\"\n",
    "SELECT Isbn\n",
    "    , Title\n",
    "    , Publisher\n",
    "    , Author\n",
    "FROM \n",
    "    Isbn.Bibliography\n",
    "\"\"\"\n",
    "# Echange Rate\n",
    "exchange_rate = \"\"\"\n",
    "SELECT \n",
    "    name,\n",
    "    rate\n",
    "FROM dbo.XChange\n",
    "\"\"\"\n",
    "#Supplier Mega List\n",
    "megalist_sql = \"\"\"\n",
    "SELECT \n",
    "    [ISBN]\n",
    "    ,[Supplier]\n",
    "    ,[Publisher]\n",
    "    ,[Currency]\n",
    "    ,[ListPrice]\n",
    "    ,[Discount]\n",
    "    ,[CostUnitPrice]\n",
    "    ,[MaxQtyPerOrder]\n",
    "    ,[ShipmentOrigin]\n",
    "    ,[UnitShippingCost]\n",
    "    ,[SeaFreightCost] AS sea_shipping_cost\n",
    "  FROM \n",
    "    [Process].[SupplierMegaList]\n",
    "\"\"\"\n",
    "\n",
    "#Import supplier Excel\n",
    "#Import short_discount\n",
    "#Import restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Import Dictionary and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_dict = pd.read_sql(pub_dict, proc_db)\n",
    "pub_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_dict.columns = map(str.lower, pub_dict.columns)\n",
    "pub_dict = pub_dict.fillna('N/A')\n",
    "for col in list(pub_dict.columns):\n",
    "    pub_dict[col] = pub_dict.apply(lambda x: clean_up(x[col]), axis =1)\n",
    "\n",
    "pub_dict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Import Bibliography and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMport and read biblio\n",
    "biblio = pd.read_sql(bilblo_sql, prod_db)\n",
    "biblio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biblio.columns = map(str.lower, biblio.columns)\n",
    "biblio = biblio.fillna('N/A')\n",
    "biblio['isbn'] = biblio['isbn'].astype(str)\n",
    "for col in list(biblio.columns):\n",
    "    biblio[col] = biblio.apply(lambda x: clean_up(x[col]), axis =1)\n",
    "biblio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we Merge bibliography with the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biblio2 = pd.merge(biblio, pub_dict, how='left', left_on = 'publisher', right_on = 'publisherlong' )\n",
    "biblio2.drop(columns = ['publisherlong'], inplace = True)\n",
    "biblio2.rename(columns={'publishershort': 'pub'}, inplace = True)\n",
    "biblio2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Import SupplierMegaList and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megalist = pd.read_sql(megalist_sql,proc_db)\n",
    "megalist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megalist.columns = map(str.lower, megalist.columns)\n",
    "megalist = megalist.fillna('N/A')\n",
    "megalist['isbn'] = megalist['isbn'].astype(str)\n",
    "for col in ['isbn', 'supplier', 'publisher', 'currency', 'shipmentorigin']:\n",
    "    megalist[col] = megalist.apply(lambda x: clean_up(x[col]), axis =1)\n",
    "megalist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megalist_pub = pd.merge(megalist, biblio2, how='left', on = 'isbn' )\n",
    "megalist_pub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning pub name\n",
    "megalist_pub['pub'] = np.where(\n",
    "    megalist_pub['pub'] == 'N/A'\n",
    "    , megalist_pub['publisher_x']\n",
    "    , megalist_pub['pub'])\n",
    "    \n",
    "# centralizing price in one column\n",
    "megalist_pub['price'] = np.where(megalist_pub['listprice'] == 0.00, megalist_pub['costunitprice'], megalist_pub['listprice'])\n",
    "\n",
    "#clean column names\n",
    "megalist_pub.rename(columns={'unitshippingcost': 'shipping_cost', 'maxqtyperorder': 'max_qty', 'shipmentorigin': 'origin'}, inplace = True)\n",
    "\n",
    "#Arrange columns and drop unnecessary columns\n",
    "\n",
    "megalist_pub = megalist_pub[['isbn', 'title', 'pub', 'author', 'supplier', 'currency', 'price', 'discount', 'shipping_cost','sea_shipping_cost', 'max_qty', 'origin']]\n",
    "\n",
    "megalist_pub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Import all_lp and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lp = pd.read_sql(all_lp, prod_db)\n",
    "all_lp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lp.columns = map(str.lower, all_lp.columns)\n",
    "all_lp = all_lp.fillna('N/A')\n",
    "all_lp['isbn'] = all_lp['isbn'].astype(str)\n",
    "for col in ['isbn','currency']:\n",
    "    all_lp[col] = all_lp.apply(lambda x: clean_up(x[col]), axis =1)\n",
    "\n",
    "all_lp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Get biblio with LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biblio_lp = pd.merge(all_lp, biblio2, how='left', on = 'isbn' )\n",
    "biblio_lp.drop(columns = ['pub'], inplace = True)\n",
    "biblio_lp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Import Sup_by_pub and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_pub = pd.read_excel('../../../../Vendors/.  Vendors Details\\supplier_procurement_details.xlsx',  sheet_name='pub')\n",
    "sup_pub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_pub.columns = map(str.lower, sup_pub.columns)\n",
    "sup_pub = sup_pub.fillna('N/A')\n",
    "for col in ['supplier','publisher', 'currency', 'shipmentorigin']:\n",
    "    sup_pub[col] = sup_pub.apply(lambda x: clean_up(x[col]), axis =1)\n",
    "sup_pub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 Merge Supplier by Publisher with biblio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_pub_biblio = pd.merge(biblio_lp, sup_pub, how='inner', left_on = ['currency', 'publisher'], right_on = ['currency', 'publisher'])\n",
    "sup_pub_biblio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sup_pub_biblio.rename(columns={'publisher': 'pub','shipping cost': 'shipping_cost', 'max quantity': 'max_qty', 'shipmentorigin': 'origin', 'shipping cost sea' : 'sea_shipping_cost'}, inplace = True)\n",
    "\n",
    "sup_pub_biblio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Import short_disc and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_disc = pd.read_excel(\"../../../../Vendors/. Short Discounted/all_short_discount_list.xlsx\")\n",
    "sp_disc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_disc.columns = map(str.lower, sp_disc.columns)\n",
    "sp_disc = sp_disc.fillna('N/A')\n",
    "sp_disc['isbn'] = sp_disc['isbn'].astype(str)\n",
    "for col in ['supplier', 'isbn']:\n",
    "    sp_disc[col] = sp_disc.apply(lambda x: clean_up(x[col]), axis =1)\n",
    "sp_disc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 Merge sup_pub_biblio by sp_disc with biblio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_biblio_disc = pd.merge(sup_pub_biblio, sp_disc, how='left', on = ['supplier', 'isbn'])\n",
    "sup_biblio_disc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_biblio_disc['discount'] = np.where(sup_biblio_disc['discount_y'].isna(), sup_biblio_disc['discount_x'],sup_biblio_disc['discount_y'])\n",
    "\n",
    "\n",
    "#Drop unneccessary Columns\n",
    "\n",
    "sup_biblio_disc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_biblio_disc = sup_biblio_disc[['isbn', 'title', 'pub', 'author', 'supplier', 'currency', 'price', 'discount', 'shipping_cost', 'sea_shipping_cost', 'max_qty', 'origin']]\n",
    "sup_biblio_disc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Create table for WC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_sup = biblio_lp[biblio_lp['currency'] == 'CND']\n",
    "can_sup.columns = map(str.lower, can_sup.columns)\n",
    "can_sup['supplier'] = 'WC'\n",
    "can_sup['discount'] = np.where(can_sup['price']<150, 0.1, np.where((can_sup['price'] >=150) & (can_sup['price']<200),0.12,0.14))\n",
    "can_sup['max_qty'] = 10000\n",
    "can_sup['origin'] = 'CAN'\n",
    "can_sup['shipping_cost'] = 2\n",
    "can_sup.rename(columns={'publisher': 'pub'}, inplace = True)\n",
    "can_sup['currency'] = 'CAD'\n",
    "can_sup['sea_shipping_cost'] = 2\n",
    "\n",
    "can_sup = can_sup[['isbn', 'title', 'pub', 'author', 'supplier', 'currency', 'price', 'discount', 'shipping_cost','sea_shipping_cost' , 'max_qty', 'origin']]\n",
    "\n",
    "can_sup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Append SupplierMegaLis, PublisherSuppliers and WesterCampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sup = megalist_pub.append([sup_biblio_disc, can_sup], ignore_index= True)\n",
    "\n",
    "all_sup_biblio = pd.merge(all_sup,biblio[['isbn', 'publisher']] , how='left', on = 'isbn')\n",
    "\n",
    "all_sup_biblio['pub'] = np.where(all_sup_biblio['pub'].isna(), all_sup_biblio['publisher'], all_sup_biblio['pub'])\n",
    "\n",
    "all_sup = all_sup_biblio[['isbn', 'title', 'pub', 'author', 'supplier', 'currency', 'price', 'discount', 'shipping_cost','sea_shipping_cost' , 'max_qty', 'origin']]\n",
    "all_sup['sea_shipping_cost'] = np.where( (all_sup['origin'] == 'US') | (all_sup['origin'] == 'CAN') , all_sup['shipping_cost'], all_sup['sea_shipping_cost'])\n",
    "all_sup.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add Fees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invoice Fee\n",
    "all_sup['invoice_fee'] = np.where(     # IF\n",
    "    all_sup['supplier'].str.contains('ALEK'), 0.005,   #Condition and True\n",
    "    np.where(  # IF False\n",
    "        (all_sup['supplier'].str.contains('LAURENTIU')) | (all_sup['supplier'].str.contains('SENAD')),0.02,   #Condition and True\n",
    "        np.where(  #IF FALSE\n",
    "            (all_sup['supplier'].str.contains('ARMANDO')) | (all_sup['supplier'].str.contains('FELIPE')),0.01, #Condition and True\n",
    "            np.where(   #IF FALSE\n",
    "                (all_sup['supplier'] == 'COINFO'), -1/11, #Condition and True\n",
    "                0)   # FALSE\n",
    "                )\n",
    "                )\n",
    "                )\n",
    "# lp_fee\n",
    "\n",
    "all_sup['lp_fee'] = np.where(\n",
    "    (all_sup['supplier'].str.contains('BILLSON') & (all_sup['discount'] == 0 )), 0.03,0)\n",
    "\n",
    "all_sup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. import and Merge exchage rate with all suppliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exch_df = pd.read_sql(exchange_rate,proc_db)\n",
    "exch_df.rename(columns={'name': 'currency'}, inplace = True)\n",
    "all_sup_exc = pd.merge(all_sup, exch_df, how='left', on = 'currency')\n",
    "all_sup_exc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cost Before exchange rate and landed cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sup_exc['inv_price_before_exc'] = all_sup_exc['price']*(1-all_sup_exc['discount']+all_sup_exc['lp_fee']*(1+all_sup_exc['invoice_fee']))\n",
    "all_sup_exc['regular_landed_cost'] = all_sup_exc['inv_price_before_exc'] * all_sup_exc['rate'] + all_sup_exc['shipping_cost']\n",
    "all_sup_exc['sea_landed_cost'] = all_sup_exc['inv_price_before_exc'] * all_sup_exc['rate'] + all_sup_exc['sea_shipping_cost']\n",
    "all_sup_exc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = pd.read_excel(\"../../../../Vendors/. Restrictions\\All Restricted List.xlsx\")\n",
    "rest.columns = map(str.lower, rest.columns)\n",
    "rest.rename(columns={'isbn13': 'isbn'}, inplace = True)\n",
    "rest['isbn'] = rest['isbn'].astype(str)\n",
    "for col in ['isbn', 'vendor']:\n",
    "    rest[col] = rest.apply(lambda x: clean_up(x[col]), axis =1)\n",
    "\n",
    "rest = rest[['isbn','vendor']]\n",
    "rest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restricted to all suppliers\n",
    "risky = rest[rest['vendor'] == 'RISKY']\n",
    "all_sup_exc = all_sup_exc[~all_sup_exc['isbn'].isin(list(risky['isbn']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restriction per supplier\n",
    "all_rest = pd.merge(all_sup_exc, rest, how='left', left_on = ['isbn','supplier'], right_on = ['isbn', 'vendor'] )\n",
    "all_rest[~(all_rest['vendor'].isna())].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Getting all posible orders for cost_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rest.drop(\n",
    "    all_rest[\n",
    "        (all_rest['supplier'] == all_rest['vendor'])\n",
    "        ].index, inplace = True\n",
    ")\n",
    "all_rest.drop(columns=['vendor'], inplace = True)\n",
    "all_rest = all_rest.sort_values(by=['regular_landed_cost'])\n",
    "all_rest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rest = all_rest.fillna('N/A')\n",
    "all_rest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Getting suppliers from UK, CAN, US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_filter = all_rest[\n",
    "    (all_rest['origin'] == 'UK')\n",
    "    | (all_rest['origin'] == 'US')\n",
    "    | (all_rest['origin'] == 'CAN')\n",
    "    ]\n",
    "\n",
    "first_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isbn_list = ['9780134610993',\n",
    "'9780803677074',\n",
    "'9781284178418',\n",
    "'9780803669260',\n",
    "'9780134752556',\n",
    "'9780323639088',\n",
    "'9781492571186',\n",
    "'9781138683143',\n",
    "'9780789760500',\n",
    "'9781496396273',\n",
    "'9780803677111',\n",
    "'9781544355658',\n",
    "'9780803661134',\n",
    "'9781544331430',\n",
    "'9780803676787',\n",
    "'9781544325040',\n",
    "'9781138088870',\n",
    "'9780323611077',\n",
    "'9781506379616',\n",
    "'9780803675797',\n",
    "'9780803679917',\n",
    "'9780803690141',\n",
    "'9780803674882',\n",
    "'9780323597791',\n",
    "'9780803676459',\n",
    "'9781719640022',\n",
    "'9780803694736',\n",
    "'9781319216801',\n",
    "'9781319216801',\n",
    "'9781319184568',\n",
    "'9780134641690',\n",
    "'9780133953145',\n",
    "'9780134475585',\n",
    "'9781118334324',\n",
    "'9781285740621',\n",
    "'9781285741550',\n",
    "'9781118875865',\n",
    "'9780134169040',\n",
    "'9781305965720',\n",
    "'9781111344191',\n",
    "'9780393640342',\n",
    "'9780134112107',\n",
    "'9781319059811',\n",
    "'9780132273589',\n",
    "'9780134113593',\n",
    "'9780077862510',\n",
    "'9780321962584',\n",
    "'9781133591887',\n",
    "'9780323312073',\n",
    "'9780073384429',\n",
    "'9781133586845',\n",
    "'9780321949912',\n",
    "'9780803658783',\n",
    "'9780763763381',\n",
    "'9780534602710',\n",
    "'9780073385372',\n",
    "'9780763756093',\n",
    "'9781584265306',\n",
    "'9781584265320',\n",
    "'9781584265290',\n",
    "'9780199591152',\n",
    "'9781416406914',\n",
    "'9780323479820',\n",
    "'9780078026881',\n",
    "'9780323402101',\n",
    "'9780803661158',\n",
    "'9781138819078',\n",
    "'9781259677588',\n",
    "'9781260494198',\n",
    "'9781138229778',\n",
    "'9780073513942',\n",
    "'9781405184588',\n",
    "'9780849342707',\n",
    "'9780060786830',\n",
    "'9780316113502',\n",
    "'9780465026425',\n",
    "'9780465052714',\n",
    "'9780465026425',\n",
    "'9780465062980',\n",
    "'9780446404662',\n",
    "'9780812972764',\n",
    "'9781599637594',\n",
    "'9780688184742',\n",
    "'9780306810121'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_us_can = first_filter[first_filter['isbn'].isin(isbn_list)]\n",
    "uk_us_can.to_csv('retail/uk_us_can.csv', index= False)\n",
    "# all_suppliers = all_rest[all_rest['isbn'].isin(isbn_list)]\n",
    "# all_suppliers.to_csv('retail/all_suppliers.csv', index= False)\n",
    "# elsevier = all_rest[all_rest['pub'].str.contains('ELSEVIER')]\n",
    "# elsevier.to_csv('retail/elsevier.csv', index= False)\n",
    "elsevier_cengage = all_rest[all_rest['pub'].str.contains('CENG') | all_rest['pub'].str.contains('ELSE')]\n",
    "# elsevier_cengage.drop_duplicates(subset =\"isbn\", keep = False, inplace = True) \n",
    "elsevier_cengage.to_csv('retail/elsevier_cengage.csv', index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_rest.to_csv('important_files/python/ca_results.csv', index= False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}