{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc # SQL Connection\n",
    "import sqlCredentials as sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(phrase):\n",
    "    phrase = phrase.lstrip()\n",
    "    phrase = phrase.rstrip()\n",
    "    phrase = phrase.upper()\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BookXCenterProduction\n",
    "prod_db = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'Server=52.86.56.66;'\n",
    "    'Database=BookXCenterProduction;'\n",
    "    'UID='+sql.username+';'\n",
    "    'PWD='+sql.password+';'\n",
    "    'Trusted_connection=no;'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_sql = \"\"\"\n",
    "SELECT\n",
    "\t[MostRecent]\n",
    "\t,[BPName]\n",
    "\t,[DocName]\n",
    "\t,[ISBN]\n",
    "      ,[Currency]\n",
    "\t,[DateAdded] AS 'po_date'\n",
    "\t,[PostingDate] AS 'receiving_date'\n",
    "  FROM [BookXCenterProduction].[SAP].[GoodsReceiptReportView]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving = pd.read_sql(receiving_sql, prod_db)\n",
    "receiving.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving['Currency'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving.drop('MostRecent', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving.dropna(inplace = True)\n",
    "receiving.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_names = pd.read_excel(\"important_files/Supplier Names .xlsx\")\n",
    "sup_names.drop(columns = ['AvgLeadTime'], inplace = True)\n",
    "sup_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Cleaning Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sup_names\n",
    "sup_names.columns = map(str.lower, sup_names.columns)\n",
    "sup_names = sup_names.fillna('N/A')\n",
    "for col in ['supplier sap name', 'supplier nickname']:\n",
    "    sup_names[col] = sup_names.apply(lambda x: clean_up(x[col]), axis =1)\n",
    "sup_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receiving\n",
    "receiving.columns = map(str.lower, receiving.columns)\n",
    "receiving = receiving.fillna('N/A')\n",
    "receiving['isbn'] = receiving['isbn'].astype(str)\n",
    "for col in ['docname', 'isbn', 'bpname']:\n",
    "    receiving[col] = receiving.apply(lambda x: clean_up(x[col]), axis =1)\n",
    "receiving['currency'] = np.where((receiving['currency'] == '') | (receiving['currency'] == '$'), 'USD', receiving['currency'])\n",
    "receiving.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier = pd.merge(receiving, sup_names, how='left', left_on = 'bpname', right_on = 'supplier sap name')\n",
    "receiving_suplier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier.drop(columns = ['bpname', 'supplier sap name'], inplace = True)\n",
    "receiving_suplier.rename(columns={'supplier nickname': 'supplier'}, inplace = True)\n",
    "receiving_suplier.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = pd.read_csv('important_files/python/ca_results.csv')\n",
    "ca.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliography\n",
    "bilblo_sql = \"\"\"\n",
    "SELECT Isbn\n",
    "    , Publisher\n",
    "FROM \n",
    "    Isbn.Bibliography\n",
    "\"\"\"\n",
    "biblio = pd.read_sql(bilblo_sql, prod_db)\n",
    "biblio.columns = map(str.lower, biblio.columns)\n",
    "biblio = biblio.fillna('N/A')\n",
    "biblio['isbn'] = biblio['isbn'].astype(str)\n",
    "for col in list(biblio.columns):\n",
    "    biblio[col] = biblio.apply(lambda x: clean_up(x[col]), axis =1)\n",
    "biblio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier_pub = pd.merge(receiving_suplier, biblio, how='left', on= 'isbn')\n",
    "receiving_suplier_pub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier_pub['lead_days'] =  receiving_suplier_pub['receiving_date'] - receiving_suplier_pub['po_date']\n",
    "receiving_suplier_pub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier_pub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier_pub_regular = receiving_suplier_pub[~receiving_suplier_pub['docname'].str.contains('SEA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier_pub_regular.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier_pub_regular['timestamp'] = receiving_suplier_pub_regular['lead_days'].astype(str).str.split(' ').str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier_pub_regular.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_suplier_pub_regular['timestamp'] = np.where(receiving_suplier_pub_regular['timestamp'] <6*7, 6*7, receiving_suplier_pub_regular['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alek_mcgraw = receiving_suplier_pub_regular[(receiving_suplier_pub_regular['supplier'] == 'ALEK') & (receiving_suplier_pub_regular['publisher'] == 'MCGRAW')]\n",
    "alek_mcgraw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alek_mcgraw['Q1'] = alek_mcgraw['timestamp'].quantile(0.25)\n",
    "alek_mcgraw['Q3'] = alek_mcgraw['timestamp'].quantile(0.75)\n",
    "alek_mcgraw['IQR'] = alek_mcgraw['Q3'] - alek_mcgraw['Q1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alek_mcgraw['outlier'] = np.where(\n",
    "    (\n",
    "        (alek_mcgraw['timestamp'] > (alek_mcgraw['Q1'] - alek_mcgraw['IQR']*1.5))\n",
    "    | (alek_mcgraw['timestamp'] < (alek_mcgraw['Q3'] + alek_mcgraw['IQR']*1.5))\n",
    "    ), 'OK', 'OUTLIER'\n",
    ")\n",
    "alek_mcgraw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alek_mcgraw[alek_mcgraw['outlier'] == 'OK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "quant_an = pd.DataFrame(columns = ['supplier','publisher','timestamp', 'min', 'avg', 'max'])\n",
    "for supplier in list(receiving_suplier_pub_regular['supplier'].unique()) :\n",
    "    for publisher in list(receiving_suplier_pub_regular['publisher'].unique()) :\n",
    "        quant_time = receiving_suplier_pub_regular[(receiving_suplier_pub_regular['supplier'] == supplier) & (receiving_suplier_pub_regular['publisher'] == publisher)]\n",
    "        quant_time['Q1'] = quant_time['timestamp'].quantile(0.25)\n",
    "        quant_time['Q3'] = quant_time['timestamp'].quantile(0.75)\n",
    "        quant_time['IQR'] = quant_time['Q3'] - quant_time['Q1']\n",
    "        quant_time['outlier'] = np.where(\n",
    "            (quant_time['timestamp'] > (quant_time['Q1'] - quant_time['IQR']*1.5))\n",
    "            | (quant_time['timestamp'] < (quant_time['Q3'] + quant_time['IQR']*1.5)\n",
    "            ), 'OK', 'OUTLIER'\n",
    "            )\n",
    "        sup_pub_days = quant_time[quant_time['outlier'] == 'OK'][['supplier', 'publisher','timestamp']]\n",
    "        sup_pub_days['min'] = sup_pub_days['timestamp'].min()\n",
    "        sup_pub_days['avg'] = sup_pub_days['timestamp'].mean()\n",
    "        sup_pub_days['max'] = sup_pub_days['timestamp'].max()\n",
    "        quant_an = quant_an.append(sup_pub_days)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_an.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = quant_an[['supplier', 'publisher', 'min', 'avg', 'max']].drop_duplicates(subset= ['supplier', 'publisher'], keep = 'first', ignore_index= True)\n",
    "unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique.to_csv('important_files/python/lead_time.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}